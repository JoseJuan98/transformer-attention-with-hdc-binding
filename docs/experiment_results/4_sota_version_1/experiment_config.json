{
    "experiment_name": "time_series_classification_sota",
    "task": "time series classification",
    "model_configs": {
        "Linear Convolutional Sinusoidal PE TS Transformer (Baseline)": {
            "model_name": "linear_conv_sinusoidal",
            "desc": "Encoder Only Transformer with Linear Projection Embeddings, Absolute Sinusoidal Positional Encoding and Convolutional Binding for Time Series Classification",
            "model": "encoder-only-transformer",
            "num_epochs": 100,
            "learning_rate": 0.003,
            "d_model": 64,
            "num_heads": 8,
            "d_ff": 256,
            "num_layers": 1,
            "dropout": 0.1,
            "positional_encoding": {
                "type": "sinusoidal",
                "learnable": false
            },
            "embedding_binding": "convolutional",
            "embedding": "linear_projection",
            "multihead_attention": "standard"
        },
        "Linear Convolutional Adaptive Sinusoidal PE TS Transformer": {
            "model_name": "linear_conv_adaptive_sin_pe",
            "desc": "Encoder Only Transformer with Linear Projection Embeddings, Adaptive Sinusoidal PE and Convolutional Binding for Time Series Classification",
            "model": "encoder-only-transformer",
            "num_epochs": 100,
            "learning_rate": 0.003,
            "d_model": 64,
            "num_heads": 8,
            "d_ff": 256,
            "num_layers": 1,
            "dropout": 0.1,
            "positional_encoding": "adaptive_sinusoidal",
            "embedding_binding": "convolutional",
            "embedding": "linear_projection",
            "multihead_attention": "standard"
        },
        "Linear Rotary Positional Embeddings (RoPE) TS Transformer": {
            "model_name": "linear_rope",
            "desc": "Encoder Only Transformer with Linear Projection Embeddings and Rotary Positional Embeddings (RoPE) for Time Series Classification",
            "model": "encoder-only-transformer",
            "num_epochs": 100,
            "learning_rate": 0.003,
            "d_model": 64,
            "num_heads": 8,
            "d_ff": 256,
            "num_layers": 1,
            "dropout": 0.1,
            "positional_encoding": "rotary",
            "embedding_binding": "identity",
            "embedding": "linear_projection",
            "multihead_attention": "rotary"
        },
        "ConvTran Adapted": {
            "model_name": "convtran",
            "desc": "ConvTran from Fouami et al. adapted for architectural consistency.",
            "model": "encoder-only-transformer",
            "num_epochs": 100,
            "learning_rate": 0.003,
            "d_model": 64,
            "num_heads": 8,
            "d_ff": 256,
            "num_layers": 1,
            "dropout": 0.1,
            "positional_encoding": "tape",
            "embedding_binding": "additive",
            "embedding": "spatial_temporal",
            "multihead_attention": "erpe"
        },
        "Linear Multi-Head Latent Attention (MLA) TS Transformer": {
            "model_name": "linear_mla",
            "desc": "Encoder Only Transformer with Linear Projection Embeddings and Multi-Head Latent Attention (MLA) for Time Series Classification",
            "model": "encoder-only-transformer",
            "num_epochs": 100,
            "learning_rate": 0.003,
            "d_model": 64,
            "num_heads": 8,
            "d_ff": 256,
            "num_layers": 1,
            "dropout": 0.1,
            "positional_encoding": "rotary",
            "embedding_binding": "identity",
            "embedding": "linear_projection",
            "multihead_attention": {
                "type": "mla",
                "qk_rope_head_dim": 4,
                "q_lora_rank": 96,
                "kv_lora_rank": 32,
                "v_head_dim": 8
            }
        }
    },
    "dataset_names": [
        "FaceDetection",
        "InsectWingbeat",
        "PenDigits",
        "SpokenArabicDigits",
        "LSST",
        "FingerMovements",
        "MotorImagery",
        "SelfRegulationSCP1",
        "Heartbeat",
        "SelfRegulationSCP2",
        "PhonemeSpectra",
        "EthanolConcentration",
        "HandMovementDirection",
        "PEMS-SF",
        "RacketSports",
        "Epilepsy",
        "NATOPS",
        "UWaveGestureLibraryAll",
        "Libras",
        "ArticularyWordRecognition",
        "BasicMotions",
        "DuckDuckGeese",
        "Cricket",
        "Handwriting",
        "ERing",
        "AtrialFibrillation",
        "StandWalkJump"
    ],
    "description": "Time Series Classification State-of-the-Art (SOTA) Experiment. Different SOTA models with N_L=1, d_model=64, d_ff=256, num_heads=8, dropout=0.1: ConvTran, DeepSeek",
    "run_version": "sota_version_1",
    "trials_per_experiment": 10,
    "default_batch_size": 64,
    "accelerator": "auto",
    "precision": "16-mixed",
    "auto_scale_batch_size": true,
    "metrics_mode": "append",
    "profiler": false,
    "summary": false,
    "plots": true,
    "development": false,
    "validation_split": 0.2,
    "early_stopping_patience": 10,
    "accumulate_grad_batches": 64,
    "gradient_clip_val": 4.0,
    "gradient_clip_algorithm": "norm",
    "use_swa": false,
    "swa_learning_rate": 0.0005,
    "use_lr_finder": true,
    "lr_finder_milestones": [
        10,
        20,
        30,
        50,
        75
    ],
    "preprocessing_only": false
}
